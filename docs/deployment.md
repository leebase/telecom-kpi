# ðŸš€ Production Deployment Guide: Telecom KPI Dashboard

## ðŸ“‹ Overview

This deployment guide provides comprehensive procedures for deploying the Telecom KPI Dashboard to production environments. It covers infrastructure setup, security configuration, performance optimization, and operational procedures for enterprise-grade deployments.

## ðŸ—ï¸ Deployment Architecture

### Recommended Production Architecture

```
Production Environment:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancer (HTTPS/SSL Termination)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Application Server (Streamlit + Python)                â”‚
â”‚ â”œâ”€â”€ Telecom KPI Dashboard                              â”‚
â”‚ â”œâ”€â”€ Health Check Endpoints                             â”‚
â”‚ â”œâ”€â”€ Feature Flag Management                            â”‚
â”‚ â””â”€â”€ Configuration Management                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Database Layer                                          â”‚
â”‚ â”œâ”€â”€ PostgreSQL/Snowflake (Primary)                     â”‚
â”‚ â”œâ”€â”€ Connection Pooling                                 â”‚
â”‚ â””â”€â”€ Backup & Recovery                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ External Services                                       â”‚
â”‚ â”œâ”€â”€ OpenRouter LLM API                                 â”‚
â”‚ â”œâ”€â”€ Monitoring & Logging                               â”‚
â”‚ â””â”€â”€ Secrets Management                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Deployment Options

#### **Option 1: Cloud Platform Deployment (Recommended)**
- **Platforms**: AWS, Azure, GCP, Heroku
- **Benefits**: Managed infrastructure, auto-scaling, integrated monitoring
- **Use Case**: Enterprise deployments with high availability requirements

#### **Option 2: Container Deployment**
- **Platforms**: Docker, Kubernetes, OpenShift
- **Benefits**: Consistent environments, easy scaling, version management
- **Use Case**: Multi-environment deployments, microservices architecture

#### **Option 3: Traditional Server Deployment**
- **Platforms**: Linux servers, VMs, bare metal
- **Benefits**: Full control, cost optimization, custom configurations
- **Use Case**: On-premises deployments, specific compliance requirements

## ðŸ›¡ï¸ Pre-Deployment Security Setup

### 1. Environment Security Configuration

#### **Required Environment Variables**
```bash
# Production Environment Configuration
export ENVIRONMENT=production
export LOG_LEVEL=INFO
export DATABASE_URL=postgresql://username:password@host:5432/telecom_dashboard
export LLM_API_KEY=sk-or-v1-your-production-api-key

# Security Feature Flags
export FEATURE_SECURITY_HEADERS=true
export FEATURE_RATE_LIMITING=true
export FEATURE_SQL_INJECTION_PROTECTION=true
export FEATURE_PII_SCRUBBING=true
export FEATURE_STRUCTURED_LOGGING=true

# Performance Configuration
export CACHE_TTL_SECONDS=300
export FEATURE_CIRCUIT_BREAKER=true
export FEATURE_CONNECTION_POOLING=true
```

#### **Security Validation**
```bash
# Pre-deployment security check
python config_validator.py production-check

# Expected output should show:
# ðŸŽ¯ Overall Production Readiness: âœ… READY
```

### 2. Secrets Management

#### **Option A: Environment Variables (Simple)**
```bash
# Set in deployment environment
export LLM_API_KEY=sk-or-v1-your-api-key
export DATABASE_URL=postgresql://secure-connection-string
```

#### **Option B: Secrets Management Service (Recommended)**
```bash
# AWS Secrets Manager
aws secretsmanager get-secret-value --secret-id telecom-dashboard/api-key

# Azure Key Vault
az keyvault secret show --vault-name telecom-vault --name api-key

# Kubernetes Secrets
kubectl create secret generic telecom-secrets \
  --from-literal=llm-api-key=sk-or-v1-your-api-key \
  --from-literal=database-url=postgresql://connection-string
```

### 3. SSL/TLS Configuration

#### **SSL Certificate Setup**
```bash
# Let's Encrypt (Recommended for public deployments)
certbot --nginx -d your-dashboard-domain.com

# Or use cloud provider managed certificates
# AWS Certificate Manager, Azure Certificate Service, etc.
```

## ðŸ³ Container Deployment

### Dockerfile
```dockerfile
# Dockerfile
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user for security
RUN useradd --create-home --shell /bin/bash appuser && \
    chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8501

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8501/?health=simple || exit 1

# Start application
CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### Docker Compose (Development/Staging)
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  telecom-dashboard:
    build: .
    ports:
      - "8501:8501"
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - FEATURE_STRUCTURED_LOGGING=true
      - FEATURE_SECURITY_HEADERS=true
    env_file:
      - .env.production
    volumes:
      - ./data:/app/data:ro
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/?health=simple"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgresql:
    image: postgres:14
    environment:
      POSTGRES_DB: telecom_dashboard
      POSTGRES_USER: telecom_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data/setup_telecom_db.sql:/docker-entrypoint-initdb.d/01-init.sql
    restart: unless-stopped

volumes:
  postgres_data:
```

### Kubernetes Deployment
```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: telecom-dashboard
  labels:
    app: telecom-dashboard
spec:
  replicas: 3
  selector:
    matchLabels:
      app: telecom-dashboard
  template:
    metadata:
      labels:
        app: telecom-dashboard
    spec:
      containers:
      - name: telecom-dashboard
        image: telecom-dashboard:latest
        ports:
        - containerPort: 8501
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: LOG_LEVEL
          value: "INFO"
        - name: LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: telecom-secrets
              key: llm-api-key
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: telecom-secrets
              key: database-url
        livenessProbe:
          httpGet:
            path: /?health=simple
            port: 8501
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /?health=detailed
            port: 8501
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 512Mi

---
apiVersion: v1
kind: Service
metadata:
  name: telecom-dashboard-service
spec:
  selector:
    app: telecom-dashboard
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8501
  type: LoadBalancer
```

## â˜ï¸ Cloud Platform Deployment

### AWS Deployment

#### **AWS ECS with Fargate**
```json
{
  "family": "telecom-dashboard",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "telecom-dashboard",
      "image": "your-account.dkr.ecr.region.amazonaws.com/telecom-dashboard:latest",
      "portMappings": [
        {
          "containerPort": 8501,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "ENVIRONMENT", "value": "production"},
        {"name": "LOG_LEVEL", "value": "INFO"}
      ],
      "secrets": [
        {
          "name": "LLM_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:telecom/api-key"
        }
      ],
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8501/?health=simple || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      },
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/telecom-dashboard",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

#### **AWS Application Load Balancer Configuration**
```bash
# Create target group
aws elbv2 create-target-group \
  --name telecom-dashboard-tg \
  --protocol HTTP \
  --port 8501 \
  --vpc-id vpc-12345678 \
  --health-check-path "/?health=simple" \
  --health-check-interval-seconds 30

# Create load balancer
aws elbv2 create-load-balancer \
  --name telecom-dashboard-alb \
  --subnets subnet-12345678 subnet-87654321 \
  --security-groups sg-12345678
```

### Azure Deployment

#### **Azure Container Instances**
```yaml
# azure-container-group.yaml
apiVersion: '2021-03-01'
location: East US
name: telecom-dashboard
properties:
  containers:
  - name: telecom-dashboard
    properties:
      image: telecomdashboard.azurecr.io/telecom-dashboard:latest
      ports:
      - port: 8501
        protocol: TCP
      environmentVariables:
      - name: ENVIRONMENT
        value: production
      - name: LOG_LEVEL
        value: INFO
      - name: LLM_API_KEY
        secureValue: ${LLM_API_KEY}
      resources:
        requests:
          cpu: 0.5
          memoryInGb: 1
  osType: Linux
  ipAddress:
    type: Public
    ports:
    - protocol: TCP
      port: 8501
  restartPolicy: Always
```

### Google Cloud Platform Deployment

#### **Cloud Run Deployment**
```bash
# Build and deploy to Cloud Run
gcloud builds submit --tag gcr.io/project-id/telecom-dashboard

gcloud run deploy telecom-dashboard \
  --image gcr.io/project-id/telecom-dashboard \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 8501 \
  --set-env-vars ENVIRONMENT=production,LOG_LEVEL=INFO \
  --set-secrets LLM_API_KEY=telecom-api-key:latest \
  --cpu 1 \
  --memory 1Gi \
  --max-instances 10
```

## ðŸ—„ï¸ Database Setup

### PostgreSQL Production Setup

#### **Database Creation and Configuration**
```sql
-- Create database and user
CREATE DATABASE telecom_dashboard;
CREATE USER telecom_user WITH ENCRYPTED PASSWORD 'secure_password';
GRANT ALL PRIVILEGES ON DATABASE telecom_dashboard TO telecom_user;

-- Connect to telecom_dashboard database
\c telecom_dashboard;

-- Run schema setup
\i setup_telecom_data_warehouse_final.sql;

-- Grant permissions
GRANT ALL ON ALL TABLES IN SCHEMA public TO telecom_user;
GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO telecom_user;

-- Create indexes for performance
CREATE INDEX idx_network_metrics_date ON fact_network_metrics_v12 (date_id);
CREATE INDEX idx_customer_experience_date ON fact_customer_experience (date_id);
CREATE INDEX idx_revenue_date ON fact_revenue (date_id);
```

#### **Connection Pooling Configuration**
```python
# production_database_config.py
DATABASE_CONFIG = {
    'postgresql': {
        'host': 'prod-postgres.company.com',
        'port': 5432,
        'database': 'telecom_dashboard',
        'user': 'telecom_user',
        'password': os.getenv('DB_PASSWORD'),
        'pool_size': 10,
        'max_overflow': 20,
        'pool_timeout': 30,
        'pool_recycle': 3600,
        'pool_pre_ping': True
    }
}
```

### Snowflake Production Setup

#### **Snowflake Configuration**
```sql
-- Create warehouse
CREATE WAREHOUSE TELECOM_WH WITH 
  WAREHOUSE_SIZE = 'MEDIUM'
  AUTO_SUSPEND = 300
  AUTO_RESUME = TRUE;

-- Create database and schema
CREATE DATABASE TELECOM_DASHBOARD;
USE DATABASE TELECOM_DASHBOARD;
CREATE SCHEMA TELECOM_SCHEMA;

-- Create user and role
CREATE ROLE TELECOM_ROLE;
CREATE USER telecom_user PASSWORD = 'secure_password' DEFAULT_ROLE = TELECOM_ROLE;
GRANT ROLE TELECOM_ROLE TO USER telecom_user;

-- Grant permissions
GRANT USAGE ON WAREHOUSE TELECOM_WH TO ROLE TELECOM_ROLE;
GRANT ALL ON DATABASE TELECOM_DASHBOARD TO ROLE TELECOM_ROLE;
GRANT ALL ON SCHEMA TELECOM_SCHEMA TO ROLE TELECOM_ROLE;
```

#### **Snowflake Connection Configuration**
```bash
# Environment variables for Snowflake
export DATABASE_URL="snowflake://telecom_user:password@account.region.snowflakecomputing.com/TELECOM_DASHBOARD/TELECOM_SCHEMA?warehouse=TELECOM_WH"
export FEATURE_SNOWFLAKE_QUERY_TAGGING=true
```

## âš™ï¸ Production Configuration

### Application Configuration

#### **Production config.secrets.yaml**
```yaml
# Production configuration
llm:
  provider: "openrouter"
  api_key: "${LLM_API_KEY}"  # From environment or secrets manager
  model: "openai/gpt-4-1106-preview"
  temperature: 0.3  # Lower temperature for consistent production responses
  max_tokens: 1000
  api_base: "https://openrouter.ai/api/v1"
  timeout: 30

database:
  path: "${DATABASE_URL}"  # PostgreSQL or Snowflake connection
  backup_enabled: true
  backup_interval_hours: 6
  connection_timeout: 30

features:
  # AI and ML Features
  ai_insights: true
  ai_insights_beta: false  # Disable beta features in production
  pii_scrubbing: true

  # Performance Features
  cache_ttl: true
  circuit_breaker: true
  connection_pooling: true

  # Enterprise Features
  structured_logging: true
  snowflake_query_tagging: true
  health_checks_detailed: true

  # Security Features (ALL MUST BE TRUE)
  security_headers: true
  rate_limiting: true
  sql_injection_protection: true

  # Development Features (ALL MUST BE FALSE)
  debug_mode: false
  test_mode: false

validation:
  required_production_vars:
    - "ENVIRONMENT"
    - "DATABASE_URL"
    - "LLM_API_KEY"
    - "LOG_LEVEL"
```

### Logging Configuration

#### **Production Logging Setup**
```bash
# Enable structured logging for production
export FEATURE_STRUCTURED_LOGGING=true
export LOG_LEVEL=INFO

# Ensure log directory exists
mkdir -p logs
chmod 755 logs
```

#### **Log Rotation Configuration**
```bash
# /etc/logrotate.d/telecom-dashboard
/path/to/telecom-dashboard/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 appuser appuser
    postrotate
        /bin/kill -HUP `cat /path/to/telecom-dashboard/app.pid 2> /dev/null` 2> /dev/null || true
    endscript
}
```

## ðŸ”„ Deployment Process

### 1. Pre-Deployment Checklist

```bash
#!/bin/bash
# pre-deployment-checklist.sh

echo "=== Pre-Deployment Checklist ==="

# 1. Code Quality
echo "1. Running linting and tests..."
python -m ruff check . || exit 1
python -m pytest tests/ -v || exit 1

# 2. Security Validation
echo "2. Validating security configuration..."
python config_validator.py production-check || exit 1

# 3. Feature Flag Validation
echo "3. Checking production feature flags..."
python config_validator.py features | grep "âŒ OFF" | grep -E "(security|injection|pii)" && {
    echo "âŒ Critical security features are disabled"
    exit 1
}

# 4. Database Migration Check
echo "4. Validating database schema..."
python -c "
from database_connection import TelecomDatabase
db = TelecomDatabase()
conn = db.get_connection()
if conn:
    print('âœ… Database connection successful')
else:
    print('âŒ Database connection failed')
    exit(1)
"

# 5. External Dependencies
echo "5. Testing external API connectivity..."
curl -s https://openrouter.ai/api/v1/models > /dev/null || {
    echo "âŒ OpenRouter API not accessible"
    exit 1
}

echo "âœ… Pre-deployment checklist completed successfully"
```

### 2. Blue-Green Deployment Script

```bash
#!/bin/bash
# blue-green-deployment.sh

BLUE_URL="http://blue.telecom-dashboard.internal:8501"
GREEN_URL="http://green.telecom-dashboard.internal:8501"
PRODUCTION_URL="http://telecom-dashboard.company.com"

echo "=== Blue-Green Deployment ==="

# 1. Deploy to Green Environment
echo "1. Deploying to Green environment..."
docker-compose -f docker-compose.green.yml up -d

# 2. Wait for Green to be Ready
echo "2. Waiting for Green environment to be ready..."
for i in {1..30}; do
    if curl -s "$GREEN_URL/?health=simple" | grep -q "healthy"; then
        echo "âœ… Green environment is healthy"
        break
    fi
    echo "Waiting for Green environment... ($i/30)"
    sleep 10
done

# 3. Run Health Checks on Green
echo "3. Running comprehensive health checks on Green..."
curl -s "$GREEN_URL/?health=detailed" | jq .

# 4. Switch Traffic to Green
echo "4. Switching traffic to Green environment..."
# Update load balancer configuration
# This depends on your load balancer (nginx, HAProxy, cloud LB, etc.)

# 5. Monitor Green Environment
echo "5. Monitoring Green environment for 5 minutes..."
for i in {1..5}; do
    health_status=$(curl -s -w "%{http_code}" -o /dev/null "$PRODUCTION_URL/?health=simple")
    if [ "$health_status" != "200" ]; then
        echo "âŒ Production health check failed - rolling back"
        # Switch back to Blue
        exit 1
    fi
    echo "âœ… Production health check passed ($i/5)"
    sleep 60
done

# 6. Cleanup Blue Environment
echo "6. Stopping Blue environment..."
docker-compose -f docker-compose.blue.yml down

echo "âœ… Blue-Green deployment completed successfully"
```

### 3. Rolling Deployment (Kubernetes)

```bash
#!/bin/bash
# rolling-deployment.sh

echo "=== Rolling Deployment ==="

# 1. Update deployment image
kubectl set image deployment/telecom-dashboard \
  telecom-dashboard=telecom-dashboard:${BUILD_NUMBER}

# 2. Monitor rollout
kubectl rollout status deployment/telecom-dashboard --timeout=600s

# 3. Verify deployment
kubectl get pods -l app=telecom-dashboard

# 4. Run post-deployment tests
kubectl exec -it $(kubectl get pod -l app=telecom-dashboard -o jsonpath='{.items[0].metadata.name}') \
  -- python config_validator.py production-check

echo "âœ… Rolling deployment completed successfully"
```

## ðŸ“Š Monitoring and Observability

### Health Check Endpoints

#### **Load Balancer Health Check**
```bash
# Simple health check for load balancers
curl http://localhost:8501/?health=simple

# Expected response:
# {"status": "healthy", "timestamp": "2025-08-09T12:00:00Z", "version": "2.2.0"}
```

#### **Detailed Health Check**
```bash
# Comprehensive health check for monitoring systems
curl http://localhost:8501/?health=detailed

# Expected response includes:
# - Database connectivity
# - External API status
# - System resources
# - Feature flag status
```

### Application Monitoring

#### **Prometheus Metrics Endpoint** (Optional Enhancement)
```python
# Add to app.py for Prometheus integration
from prometheus_client import start_http_server, Counter, Histogram, Gauge

# Metrics
REQUEST_COUNT = Counter('requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('request_duration_seconds', 'Request duration')
ACTIVE_USERS = Gauge('active_users', 'Number of active users')

# Start metrics server
start_http_server(8502)
```

#### **Log Aggregation**
```bash
# Filebeat configuration for ELK stack
# /etc/filebeat/filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /app/logs/*.log
  fields:
    application: telecom-dashboard
    environment: production
  json.keys_under_root: true
  json.add_error_key: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "telecom-dashboard-%{+yyyy.MM.dd}"
```

## ðŸš¨ Disaster Recovery

### Backup Procedures

#### **Database Backup**
```bash
#!/bin/bash
# database-backup.sh

BACKUP_DIR="/backups/telecom-dashboard"
DATE=$(date +%Y%m%d_%H%M%S)

# PostgreSQL backup
pg_dump -h $DB_HOST -U $DB_USER -d telecom_dashboard \
  > "$BACKUP_DIR/database_backup_$DATE.sql"

# Compress backup
gzip "$BACKUP_DIR/database_backup_$DATE.sql"

# Upload to cloud storage (AWS S3 example)
aws s3 cp "$BACKUP_DIR/database_backup_$DATE.sql.gz" \
  s3://telecom-dashboard-backups/database/

# Cleanup old backups (keep 30 days)
find $BACKUP_DIR -name "database_backup_*.sql.gz" -mtime +30 -delete

echo "âœ… Database backup completed: database_backup_$DATE.sql.gz"
```

#### **Application Backup**
```bash
#!/bin/bash
# application-backup.sh

BACKUP_DIR="/backups/telecom-dashboard"
DATE=$(date +%Y%m%d_%H%M%S)

# Backup configuration and logs
tar -czf "$BACKUP_DIR/app_backup_$DATE.tar.gz" \
  config.secrets.yaml \
  logs/ \
  data/

# Upload to cloud storage
aws s3 cp "$BACKUP_DIR/app_backup_$DATE.tar.gz" \
  s3://telecom-dashboard-backups/application/

echo "âœ… Application backup completed: app_backup_$DATE.tar.gz"
```

### Recovery Procedures

#### **Database Recovery**
```bash
#!/bin/bash
# database-recovery.sh

BACKUP_FILE=$1
if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file.sql.gz>"
    exit 1
fi

echo "=== Database Recovery ==="
echo "Backup file: $BACKUP_FILE"

# Download backup from cloud storage
aws s3 cp "s3://telecom-dashboard-backups/database/$BACKUP_FILE" .

# Decompress backup
gunzip "$BACKUP_FILE"
BACKUP_SQL="${BACKUP_FILE%.gz}"

# Restore database
echo "Restoring database from $BACKUP_SQL..."
psql -h $DB_HOST -U $DB_USER -d telecom_dashboard < "$BACKUP_SQL"

echo "âœ… Database recovery completed"
```

## ðŸ”§ Operational Procedures

### Daily Operations

#### **Daily Health Check**
```bash
#!/bin/bash
# daily-health-check.sh

echo "=== Daily Health Check - $(date) ==="

# 1. Application Health
health_status=$(curl -s "$PRODUCTION_URL/?health=detailed")
echo "Application Health: $health_status"

# 2. Database Performance
python -c "
from database_connection import TelecomDatabase
import time
start = time.time()
db = TelecomDatabase()
metrics = db.get_network_metrics()
end = time.time()
print(f'Database Query Time: {end-start:.2f}s')
print(f'Network Metrics Count: {len(metrics) if metrics else 0}')
"

# 3. Log Analysis
error_count=$(grep -c "ERROR\|CRITICAL" logs/application.log)
echo "Error Count (last 24h): $error_count"

# 4. Resource Usage
python -c "
import psutil
cpu = psutil.cpu_percent(interval=1)
memory = psutil.virtual_memory().percent
disk = psutil.disk_usage('/').percent
print(f'CPU Usage: {cpu}%')
print(f'Memory Usage: {memory}%')
print(f'Disk Usage: {disk}%')
"

echo "âœ… Daily health check completed"
```

### Weekly Maintenance

#### **Weekly Maintenance Script**
```bash
#!/bin/bash
# weekly-maintenance.sh

echo "=== Weekly Maintenance - $(date) ==="

# 1. Log Rotation
logrotate -f /etc/logrotate.d/telecom-dashboard

# 2. Database Maintenance
python -c "
# Database optimization queries
# VACUUM, REINDEX, UPDATE STATISTICS etc.
print('Database maintenance completed')
"

# 3. Security Updates
python config_validator.py production-check

# 4. Backup Verification
latest_backup=$(aws s3 ls s3://telecom-dashboard-backups/database/ | tail -1)
echo "Latest backup: $latest_backup"

# 5. Performance Baseline Update
python -c "
# Run performance benchmarks
# Update baseline metrics
print('Performance baseline updated')
"

echo "âœ… Weekly maintenance completed"
```

## ðŸ“‹ Deployment Checklist

### Pre-Deployment
- [ ] Code review completed and approved
- [ ] All tests passing (unit, integration, security)
- [ ] Security scan completed with no critical issues
- [ ] Configuration validated for production environment
- [ ] Database migrations tested
- [ ] Backup procedures verified
- [ ] Rollback plan documented

### Deployment
- [ ] Maintenance window scheduled and communicated
- [ ] Blue-green or rolling deployment executed
- [ ] Health checks passing in new environment
- [ ] Feature flags configured correctly
- [ ] Monitoring and alerting active
- [ ] Load balancer configuration updated
- [ ] SSL certificates valid and configured

### Post-Deployment
- [ ] End-to-end functionality testing completed
- [ ] Performance baseline verified
- [ ] Security features validated
- [ ] Monitoring dashboards reviewed
- [ ] Documentation updated
- [ ] Stakeholders notified of successful deployment
- [ ] Post-deployment retrospective scheduled

---

**This deployment guide should be customized for your specific infrastructure and updated after each deployment to reflect lessons learned and process improvements.**
